{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aH-OYRGoSM28"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4_ycUdtQYiU"
   },
   "source": [
    "# **Podpunkt 1.a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWj5Ze9A_lLF",
    "outputId": "4fef549c-e0ec-4145-f0b9-084f2646b61a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimalny koszt przekształcenia 'kot' w 'aforyzm' z zamianą sąsiednich znaków: 6\n"
     ]
    }
   ],
   "source": [
    "def edit_distance(x: str, y: str, costs: list):\n",
    "\n",
    "    insert_cost, delete_cost, replace_cost, swap_cost = costs  # Przypisujemy koszty z wektora\n",
    "\n",
    "    m, n = len(x), len(y)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    # Inicjalizacja pierwszego wiersza i pierwszej kolumny\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i * delete_cost\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j * insert_cost\n",
    "\n",
    "    # Wypełnianie macierzy DP\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if x[i - 1] == y[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]  # Bez kosztu, jeśli znaki są takie same\n",
    "            else:\n",
    "                dp[i][j] = min(\n",
    "                    dp[i - 1][j] + delete_cost,  # Usunięcie znaku\n",
    "                    dp[i][j - 1] + insert_cost,  # Wstawienie znaku\n",
    "                    dp[i - 1][j - 1] + replace_cost  # Zamiana znaku\n",
    "                )\n",
    "\n",
    "    return dp[m][n]\n",
    "\n",
    "# Przykład użycia\n",
    "# Lista kosztów: [insert_cost, delete_cost, replace_cost, transposition_cost]\n",
    "costs = [1, 1, 1, 1]\n",
    "\n",
    "x = \"kot\"\n",
    "y = \"aforyzm\"\n",
    "cost = edit_distance(x, y, costs)\n",
    "print(f\"Minimalny koszt przekształcenia '{x}' w '{y}' z zamianą sąsiednich znaków: {cost}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-DEyagnQdE7"
   },
   "source": [
    "# **Podpunkt 1.b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Siu36wChN5RM",
    "outputId": "903110ad-a0db-4339-8ffa-c9b92d6adbac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macierz kosztów transformacji:\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "[1, 1, 2, 2, 3, 4]\n",
      "[2, 1, 2, 3, 3, 4]\n",
      "[3, 2, 2, 2, 3, 4]\n",
      "[4, 3, 3, 3, 3, 4]\n",
      "[5, 4, 4, 4, 4, 4]\n",
      "[6, 5, 5, 5, 5, 5]\n",
      "Minimalny koszt przekształcenia 'babcia' w 'album' z zamianą sąsiednich znaków: 5\n"
     ]
    }
   ],
   "source": [
    "def edit_distance_with_transposition(x: str, y: str, costs: list, verbose = True):\n",
    "\n",
    "    insert_cost, delete_cost, replace_cost, swap_cost = costs  # Przypisujemy koszty z wektora\n",
    "\n",
    "    m, n = len(x), len(y)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    # Inicjalizacja pierwszego wiersza i pierwszej kolumny\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i * delete_cost\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j * insert_cost\n",
    "\n",
    "    # Wypełnianie macierzy DP\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if x[i - 1] == y[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]  # Bez kosztu, jeśli znaki są takie same\n",
    "             # Sprawdzamy możliwość transpozycji\n",
    "            elif i > 1 and j > 1 and x[i - 1] == y[j - 2] and x[i - 2] == y[j - 1]:\n",
    "                dp[i][j] = min(dp[i][j], dp[i - 2][j - 2] + swap_cost)\n",
    "            else:\n",
    "                dp[i][j] = min(\n",
    "                    dp[i - 1][j] + delete_cost,  # Usunięcie znaku\n",
    "                    dp[i][j - 1] + insert_cost,  # Wstawienie znaku\n",
    "                    dp[i - 1][j - 1] + replace_cost  # Zamiana znaku\n",
    "                )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Macierz kosztów transformacji:\")\n",
    "        for row in dp:\n",
    "            print(row)\n",
    "\n",
    "    return dp[m][n]\n",
    "\n",
    "# Lista kosztów: [insert_cost, delete_cost, replace_cost, transposition_cost]\n",
    "costs = [1, 1, 2, 1]\n",
    "\n",
    "x = \"babcia\"\n",
    "y = \"album\"\n",
    "cost = edit_distance_with_transposition(x, y, costs)\n",
    "print(f\"Minimalny koszt przekształcenia '{x}' w '{y}' z zamianą sąsiednich znaków: {cost}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8pz1NGrQ1rs"
   },
   "source": [
    "# **Zadanie 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMogLPzOQ5pL",
    "outputId": "d42c6ee1-550e-4972-eb49-9b8dfbc150a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macierz kosztów transformacji:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "[1, 0, 1, 2, 3, 4, 5, 6]\n",
      "[2, 1, 1, 2, 3, 4, 5, 6]\n",
      "[3, 2, 2, 2, 3, 4, 5, 6]\n",
      "[4, 3, 3, 2, 3, 4, 5, 6]\n",
      "[5, 4, 4, 3, 2, 3, 4, 5]\n",
      "[6, 5, 5, 4, 3, 2, 3, 4]\n",
      "[7, 6, 6, 5, 4, 3, 3, 4]\n",
      "[8, 7, 7, 6, 5, 4, 4, 3]\n",
      "Minimalny koszt przekształcenia 'algorytm' w 'aforyzm' z zamianą sąsiednich znaków: 3\n"
     ]
    }
   ],
   "source": [
    "x = \"algorytm\"\n",
    "y = \"aforyzm\"\n",
    "cost = edit_distance_with_transposition(x, y, costs)\n",
    "print(f\"Minimalny koszt przekształcenia '{x}' w '{y}' z zamianą sąsiednich znaków: {cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f2jPHZGRD90"
   },
   "source": [
    "# **Zadanie 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "AD3utcJNUHW6"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generateWords(amount: int, baseWord: str, max_cost: int, costs: list):\n",
    "\n",
    "    insert_cost, delete_cost, replace_cost, swap_cost = costs\n",
    "    examples = set()\n",
    "    letters = list(baseWord)\n",
    "\n",
    "    for _ in range(amount):\n",
    "        current_word = letters.copy()\n",
    "        cost = max_cost\n",
    "\n",
    "        while cost > 0:\n",
    "            action = random.randint(1, 3)\n",
    "\n",
    "            if action == 1:  # Insert\n",
    "                insert_position = random.randint(0, len(current_word))\n",
    "                insert_char = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "                current_word.insert(insert_position, insert_char)\n",
    "                cost -= insert_cost\n",
    "\n",
    "            elif action == 2:  # Delete\n",
    "                if len(current_word) > 0:\n",
    "                    delete_position = random.randint(0, len(current_word) - 1)\n",
    "                    current_word.pop(delete_position)\n",
    "                    cost -= delete_cost\n",
    "\n",
    "            else:  # Replace\n",
    "                if len(current_word) > 0:\n",
    "                    replace_position = random.randint(0, len(current_word) - 1)\n",
    "                    replace_char = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "                    current_word[replace_position] = replace_char\n",
    "                    cost -= replace_cost\n",
    "\n",
    "            examples.add(''.join(current_word))\n",
    "\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1KHYy85fWyyS",
    "outputId": "1724180a-cf02-46e0-b9fe-a1664e4267e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhelo\n",
      "hezlo\n",
      "yhello\n",
      "helo\n",
      "hezllo\n",
      "hmllo\n",
      "henlo\n",
      "helfo\n"
     ]
    }
   ],
   "source": [
    "# Lista kosztów: [insert_cost, delete_cost, replace_cost, transposition_cost]\n",
    "costs = [1, 1, 2, 1]\n",
    "\n",
    "generated_words = generateWords(5, \"hello\", 2, costs)\n",
    "\n",
    "# Wypisanie wygenerowanych słów\n",
    "for word in generated_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKsqBCxpYaij"
   },
   "source": [
    "# **Zadanie 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soKS3pFibtc0",
    "outputId": "f9ae12b1-0316-4a35-ac61-6a12c766333e"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def load_dictionary(filename: str) -> set:\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        return {line.strip().lower() for line in file}\n",
    "\n",
    "def generateWords(amount: int, baseWord: str, max_cost: int, costs: list, dictionary: set):\n",
    "    insert_cost, delete_cost, replace_cost, swap_cost = costs\n",
    "    valid_words = set()\n",
    "    letters = list(baseWord)\n",
    "\n",
    "    while len(valid_words) < amount:\n",
    "        current_word = letters.copy()\n",
    "        cost = max_cost\n",
    "\n",
    "        while cost > 0:\n",
    "            possible_actions = []\n",
    "            if cost >= insert_cost:\n",
    "                possible_actions.append(1)  # Insert\n",
    "            if cost >= delete_cost and len(current_word) > 0:\n",
    "                possible_actions.append(2)  # Delete\n",
    "            if cost >= replace_cost and len(current_word) > 0:\n",
    "                possible_actions.append(3)  # Replace\n",
    "\n",
    "            if not possible_actions:\n",
    "                break\n",
    "\n",
    "            action = random.choice(possible_actions)\n",
    "\n",
    "            if action == 1:  # Insert\n",
    "                insert_position = random.randint(0, len(current_word))\n",
    "                insert_char = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "                current_word.insert(insert_position, insert_char)\n",
    "                cost -= insert_cost\n",
    "\n",
    "            elif action == 2:  # Delete\n",
    "                delete_position = random.randint(0, len(current_word) - 1)\n",
    "                current_word.pop(delete_position)\n",
    "                cost -= delete_cost\n",
    "\n",
    "            else:  # Replace\n",
    "                replace_position = random.randint(0, len(current_word) - 1)\n",
    "                replace_char = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "                current_word[replace_position] = replace_char\n",
    "                cost -= replace_cost\n",
    "\n",
    "        word = ''.join(current_word)\n",
    "        if word in dictionary and word != baseWord:\n",
    "            valid_words.add(word)\n",
    "    \n",
    "    return valid_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hel\n",
      "elo\n",
      "hallo\n"
     ]
    }
   ],
   "source": [
    "dictionary = load_dictionary(\"slowa.txt\")\n",
    "\n",
    "costs = [1, 1, 2, 1]\n",
    "\n",
    "generated_words = generateWords(3, \"hello\", 2, costs, dictionary)\n",
    "\n",
    "for word in generated_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOYUzwVFi8ED"
   },
   "source": [
    "# **Zadanie 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "0lMGhp1Ei9lL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QH1CaNMkqbr",
    "outputId": "d46e48d4-59f5-4334-97ca-b5f054a67edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                            message\n",
      "0      0  Go until jurong point, crazy.. Available only ...\n",
      "1      0                      Ok lar... Joking wif u oni...\n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      0  U dun say so early hor... U c already then say...\n",
      "4      0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "file_path = \"SMSSpamCollection\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"label\", \"message\"])\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"message\"], df[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Użyjmy CountVectorizer do przekształcenia danych tekstowych w cechy\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-gVo8uEjAT7",
    "outputId": "f071f25a-1f0a-4e2a-ff57-e21b1a1042c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Training Time: 1.6172 seconds\n",
      "SVM F1-Score: 0.9544\n",
      "SVM accuracy: 0.9883\n"
     ]
    }
   ],
   "source": [
    "# Trening SVM\n",
    "start_time = time.time()\n",
    "svm_model = SVC(kernel='rbf', C=2.0, gamma='scale')\n",
    "svm_model.fit(X_train_vec, y_train)\n",
    "svm_train_time = time.time() - start_time\n",
    "\n",
    "svm_predictions = svm_model.predict(X_test_vec)\n",
    "\n",
    "svm_f1_score = f1_score(y_test, svm_predictions)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "\n",
    "print(f\"SVM Training Time: {svm_train_time:.4f} seconds\")\n",
    "print(f\"SVM F1-Score: {svm_f1_score:.4f}\")\n",
    "print(f\"SVM accuracy: {svm_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07PBaojejBox",
    "outputId": "9d3dc2c3-5428-4702-fbf9-2fdc6fab8f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Training Time: 0.0101 seconds\n",
      "Naive Bayes F1-Score: 0.9559\n",
      "SVM accuracy: 0.9857\n"
     ]
    }
   ],
   "source": [
    "# Trening Naive Bayes\n",
    "start_time = time.time()\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vec, y_train)\n",
    "nb_train_time = time.time() - start_time\n",
    "\n",
    "nb_predictions = nb_model.predict(X_test_vec)\n",
    "\n",
    "nb_f1_score = f1_score(y_test, nb_predictions)\n",
    "nb_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "\n",
    "print(f\"Naive Bayes Training Time: {nb_train_time:.4f} seconds\")\n",
    "print(f\"Naive Bayes F1-Score: {nb_f1_score:.4f}\")\n",
    "print(f\"SVM accuracy: {nb_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOt-8zKUmzSJ"
   },
   "source": [
    "f1-score jest podobny w obu przypadkach, delikatnie większy dla NB, jednakże czasowo NB odskakuje od SVM co moze być spowodowane mniej skomplikowanymi obliczeniami na bazie prawdopodobieństw jednak zaklada ze cechy są niezależne(naive), model SVC posiada dużo większą złożoność obliczeniową, ze względu na maksymalizację marginesu granicy decyzyjnej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-w8CTJoaodJi"
   },
   "source": [
    "# **Zadanie 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66Q7rFDVo9Lx"
   },
   "source": [
    "Klasa CA: $\\{1, 1, 2, 2, 3\\}$\n",
    "\n",
    "Klasa CB: $\\{3, 4, 4, 5, 5\\}$\n",
    "\n",
    "Słownik cech: $V = \\{1, 2, 3, 4, 5\\}$\n",
    "\n",
    "\n",
    "# **6.1 Funkcje częstości cech.**\n",
    "$f(x_i, C_k), \\text{gdzie }  x_i \\in V  (\\text{czyli wartości z słownika cech} )  \\text{i} \\ C_k  \\text{to klasa}.$\n",
    "\n",
    "---\n",
    "\n",
    "Klasa CA:\n",
    "$f(1, CA) = 2 \\quad (\\text{występuje dwa razy})$  \n",
    "$f(2, CA) = 2 \\quad (\\text{występuje dwa razy})$  \n",
    "$f(3, CA) = 1 \\quad (\\text{występuje raz})$  \n",
    "$f(4, CA) = 0 \\quad (\\text{nie występuje})$  \n",
    "$f(5, CA) = 0 \\quad (\\text{nie występuje})$\n",
    "\n",
    "Klasa CB:\n",
    "\n",
    "$f(1, CB) = 0 \\quad (\\text{nie występuje})$  \n",
    "$f(2, CB) = 0 \\quad (\\text{nie występuje})$  \n",
    "$f(3, CB) = 1 \\quad (\\text{występuje raz})$  \n",
    "$f(4, CB) = 2 \\quad (\\text{występuje dwa razy})$  \n",
    "$f(5, CB) = 2 \\quad (\\text{występuje dwa razy})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYSUv_Y9sjN5"
   },
   "source": [
    "# **6.2 Warunkowe prawdopodobieństwo.**\n",
    "\n",
    "$Prawdopodobieństwo warunkowe ( P(x_i \\mid C_k) ) obliczamy zgodnie z wzorem:$\n",
    "\n",
    "$P(x_i \\mid C_k) = \\frac{f(x_i, C_k) + \\alpha}{N_{C_k} + \\alpha \\cdot |V|}$\n",
    "\n",
    "gdzie:\n",
    "\n",
    "- $( N_{C_k} ) to całkowita liczba wystąpień cech w klasie  (C_k) ,$\n",
    "- $( |V| ) to liczba unikalnych cech w słowniku ( V ),$\n",
    "- $( \\alpha = 1 ) to parametr wygładzania Laplace’a.$\n",
    "\n",
    "---\n",
    "\n",
    "Dla CA:\n",
    "\n",
    "$f(1, CA) = \\frac{2 + 1}{5 + 1 \\cdot 5} = \\frac{3}{10} = 0.3 $  \n",
    "$f(2, CA) = \\frac{2 + 1}{5 + 1 \\cdot 5} = \\frac{3}{10} = 0.3 $  \n",
    "$f(3, CA) = \\frac{1 + 1}{5 + 1 \\cdot 5} = \\frac{2}{10} = 0.2 $  \n",
    "$f(4, CA) = \\frac{0 + 1}{5 + 1 \\cdot 5} = \\frac{1}{10} = 0.1 $  \n",
    "$f(5, CA) = \\frac{0 + 1}{5 + 1 \\cdot 5} = \\frac{1}{10} = 0.1 $\n",
    "\n",
    "\n",
    "Dla CB:\n",
    "\n",
    "$f(1, CB) = \\frac{0 + 1}{5 + 1 \\cdot 5} = \\frac{1}{10} = 0.1 $  \n",
    "$f(2, CB) = \\frac{0 + 1}{5 + 1 \\cdot 5} = \\frac{1}{10} = 0.1 $  \n",
    "$f(3, CB) = \\frac{1 + 1}{5 + 1 \\cdot 5} = \\frac{2}{10} = 0.2 $  \n",
    "$f(4, CB) = \\frac{2 + 1}{5 + 1 \\cdot 5} = \\frac{3}{10} = 0.3 $  \n",
    "$f(5, CB) = \\frac{2 + 1}{5 + 1 \\cdot 5} = \\frac{3}{10} = 0.3 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3krU2BhvDyK"
   },
   "source": [
    "Granica decyzyjna to punkt, w którym klasyfikator nie ma preferencji między klasami, czyli:\n",
    "\n",
    "$\n",
    "P(x \\mid C_A) = P(x \\mid C_B)\n",
    "$\n",
    "\n",
    "Z danych:\n",
    "\n",
    "$\n",
    "P(x \\mid C_A) = \\frac{f(x, C_A) + 1}{5 + 5}\n",
    "$\n",
    "$\n",
    "P(x \\mid C_B) = \\frac{f(x, C_B) + 1}{5 + 5}\n",
    "$\n",
    "\n",
    "Po podstawieniu wartości dla $( f(x, C_A) )$ i $( f(x, C_B) )$ z poprzednich obliczeń, otrzymujemy:\n",
    "$\n",
    "\\frac{f(x, C_A) + 1}{10} = \\frac{f(x, C_B) + 1}{10}\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "1. Dla $(x = 1)$:\n",
    "\n",
    "$\n",
    "P(1 \\mid C_A) = \\frac{2 + 1}{10} = \\frac{3}{10} = 0.3\n",
    "$\n",
    "\n",
    "$\n",
    "P(1 \\mid C_B) = \\frac{0 + 1}{10} = \\frac{1}{10} = 0.1\n",
    "$\n",
    "\n",
    "$\n",
    "P(1 \\mid C_A) \\neq P(1 \\mid C_B)\n",
    "$\n",
    "\n",
    "2. Dla $(x = 2)$:\n",
    "$\n",
    "P(2 \\mid C_A) = \\frac{2 + 1}{10} = \\frac{3}{10} = 0.3\n",
    "$\n",
    "$\n",
    "P(2 \\mid C_B) = \\frac{0 + 1}{10} = \\frac{1}{10} = 0.1\n",
    "$\n",
    "$\n",
    "P(2 \\mid C_A) \\neq P(2 \\mid C_B)\n",
    "$\n",
    "\n",
    "3. Dla $(x = 3)$:\n",
    "$\n",
    "P(3 \\mid C_A) = \\frac{1 + 1}{10} = \\frac{2}{10} = 0.2\n",
    "$\n",
    "$\n",
    "P(3 \\mid C_B) = \\frac{1 + 1}{10} = \\frac{2}{10} = 0.2\n",
    "$\n",
    "$\n",
    "P(3 \\mid C_A) = P(3 \\mid C_B)\n",
    "$\n",
    "\n",
    "4. Dla $(x = 4)$:\n",
    "$\n",
    "P(4 \\mid C_A) = \\frac{0 + 1}{10} = \\frac{1}{10} = 0.1\n",
    "$\n",
    "$\n",
    "P(4 \\mid C_B) = \\frac{2 + 1}{10} = \\frac{3}{10} = 0.3\n",
    "$\n",
    "$\n",
    "P(4 \\mid C_A) \\neq P(4 \\mid C_B)\n",
    "$\n",
    "\n",
    "5. Dla $(x = 5)$:\n",
    "$\n",
    "P(5 \\mid C_A) = \\frac{0 + 1}{10} = \\frac{1}{10} = 0.1\n",
    "$\n",
    "$\n",
    "P(5 \\mid C_B) = \\frac{2 + 1}{10} = \\frac{3}{10} = 0.3\n",
    "$\n",
    "$\n",
    "P(5 \\mid C_A) \\neq P(5 \\mid C_B)\n",
    "$\n",
    "\n",
    "\n",
    "$( P(x \\mid C_A) = P(x \\mid C_B) )$ jest spełnione tylko dla $( x = 3 )$.\n",
    "\n",
    "To oznacza, że punkt $( x = 3 )$ jest granicą decyzyjną.\n",
    "\n",
    "Dla wartości mniejszych niż 3 klasyfikator przypisuje próbki do klasy $( C_A )$, a dla wartości większych niż 3 przypisuje je do klasy $( C_B )$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-rvR-6TxSCx"
   },
   "source": [
    "**Pyt 1.**\n",
    "\n",
    "Wygładzanie Laplace’a jest stosowane, aby uniknąć problemu zerowych prawdopodobieństw, które mogą pojawić się, gdy cecha nie występuje w danej klasie.\n",
    "\n",
    "Bez wygładzenia model mógłby uznać klasę za niemożliwą do przypisania, co może prowadzić do błędnych klasyfikacji\n",
    "\n",
    "**Pyt 2.**\n",
    "\n",
    "Nowe cechy nie znajdując się w słowniku $V$ obliczy prawdopodobieństwo, które wynosiłoby zero, gdybyśmy nie użyli wygładzenia Laplaca.\n",
    "\n",
    "\n",
    "**Pyt 3.**\n",
    "\n",
    "Większa ilość cech wydłużyłaby czas potrzebny na wykonanie obliczeń prawdopodobieństwa przynależnośći do danej klasy, jednak słownik byłby bardziej złożony, w niektórych przypadkach może to polepszyć dokładność klasyfikacji do danych klas"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
