{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stop_words = set(stopwords.words('english'))\n"
      ],
      "metadata": {
        "id": "cp0QyoxYLnxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(a_set, cats):\n",
        "    dataset = fetch_20newsgroups(subset=a_set, categories=cats,\n",
        "                                remove=('headers', 'footers', 'quotes'),\n",
        "                                shuffle=True)\n",
        "    return dataset\n",
        "\n",
        "categories = [\"comp.windows.x\", \"misc.forsale\", \"rec.autos\", \"rec.motorcycles\",\n",
        "            \"rec.sport.baseball\", \"rec.sport.hockey\", \"sci.crypt\", \"sci.med\",\n",
        "            \"sci.space\", \"talk.politics.mideast\"]"
      ],
      "metadata": {
        "id": "xDOOUizbLn2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups_all = load_dataset('all', categories)\n",
        "print(f\"Loaded {len(newsgroups_all.data)} docs.\")"
      ],
      "metadata": {
        "id": "58lu6gbwLnzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    # Usuń znaki specjalne i liczby używając wyrażenia regularnego\n",
        "    text = re.sub(...)\n",
        "\n",
        "    # Podziel tekst na tokeny, usuwając stop words i stosując stemming\n",
        "    tokens = ...\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "fPFhSFbpLnu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_docs = ..."
      ],
      "metadata": {
        "id": "IX8eksTeMcj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wybierz dwa z LSA, LDA i NMF, zaimplementuj te rozwiązania i porównaj wyniki\n",
        "# wyświetl 10 tematów, porównaj je ze sobą\n",
        "# wyświetl artykuły (albo jego część np. 100 słów) dla jednego z tematów i zobacz co na jego temat mają do powiedzenia modele"
      ],
      "metadata": {
        "id": "OTv1dDWdkyQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}