{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6bc14c0d",
      "metadata": {
        "id": "6bc14c0d"
      },
      "source": [
        "\n",
        "# System Q&A z Fine-Tuningiem T5 i Retrieverem (FAISS)\n",
        "\n",
        "**Cel zadania:**  \n",
        "Stwórz system pytanie-odpowiedź (Q&A), który:\n",
        "- Wykorzystuje **Twój własny zbiór danych** (CSV: pytania, konteksty, odpowiedzi),\n",
        "- Trenuje model **T5-small** na Twoim zbiorze (fine-tuning),\n",
        "- Wyszukuje kontekst za pomocą **retrievera FAISS**,\n",
        "- Generuje odpowiedzi z pomocą fine-tunowanego modelu.\n",
        "\n",
        "---\n",
        "\n",
        "## Zadania (3 punkty):\n",
        "1) Przygotowanie własnych danych (CSV)  \n",
        "2) Fine-tuning modelu T5-small  \n",
        "3) Stworzenie retrievera FAISS + generowanie odpowiedzi  \n",
        "4) Testy i analiza wyników  \n",
        "5) Raport PDF z wnioskami\n",
        "\n",
        "Fine tuning = 1 punkt   \n",
        "RAG = 1 punkt   \n",
        "PDF = 1 punkt   \n",
        "\n",
        "**Uwaga:** Fine-tuning powinien być wykonany na **innym temacie lub zakresie pytań** niż dokumenty w retrieverze FAISS.\n",
        "Nie używaj tych samych danych w obu miejscach!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc802d6b",
      "metadata": {
        "id": "fc802d6b"
      },
      "source": [
        "\n",
        "##  Przygotowanie danych\n",
        "\n",
        "Przygotuj własny plik CSV z danymi: `question`, `context`, `answer`.\n",
        "\n",
        "Przykładowy format (przygotuj samodzielnie!):\n",
        "\n",
        "| question                      | context                                    | answer       |\n",
        "|------------------------------|--------------------------------------------|--------------|\n",
        "| What is the capital of France?| The capital of France is Paris.             | Paris        |\n",
        "| What is the currency of USA? | The currency of the USA is the dollar.      | The dollar   |"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community faiss-cpu\n",
        "#!pip install transformers datasets sentence-transformers"
      ],
      "metadata": {
        "id": "qwutOCXlXcWc"
      },
      "id": "qwutOCXlXcWc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import faiss\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "C0mcqeTYXhnh"
      },
      "id": "C0mcqeTYXhnh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a190d0df",
      "metadata": {
        "id": "a190d0df"
      },
      "outputs": [],
      "source": [
        "# Wczytaj swój plik CSV\n",
        "df = pd.read_csv(\"your_data.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfd92791",
      "metadata": {
        "id": "bfd92791"
      },
      "source": [
        "\n",
        "## Fine-tuning modelu T5-small\n",
        "**Uwaga:** Fine-tuning powinien być wykonany na **innym temacie lub zakresie pytań** niż dokumenty w retrieverze FAISS.\n",
        "Nie używaj tych samych danych w obu miejscach!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a1ea0bf",
      "metadata": {
        "id": "0a1ea0bf"
      },
      "outputs": [],
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3340a915",
      "metadata": {
        "id": "3340a915"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [f\"question: {q} context: {c}\" for q, c in zip(examples['question'], examples['context'])]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(examples[\"answer\"], max_length=128, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "129fae8a",
      "metadata": {
        "id": "129fae8a"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./t5-finetuned\",\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    save_steps=100,\n",
        "    save_total_limit=1\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sprawdź czy model jest w stanie odpowiedzieć na pytania z Twojego zbioru danych!\n",
        "# Możesz zmodyfikować parametry treningu"
      ],
      "metadata": {
        "id": "msZBdy1kZVa-"
      },
      "id": "msZBdy1kZVa-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e65e2c68",
      "metadata": {
        "id": "e65e2c68"
      },
      "source": [
        "\n",
        "## Retriever (FAISS) + Generowanie odpowiedzi\n",
        "\n",
        "Zbuduj system, który wyszukuje kontekst w dokumentach i generuje odpowiedzi.\n",
        "\n",
        "Przygotuj własną listę dokumentów do wyszukiwania (minimum 20 zdań).\n",
        "\n",
        "**Uwaga:** Twoja baza wiedzy (lista dokumentów) w retrieverze **nie powinna być taka sama jak dane do fine-tuningu**.\n",
        "Celem jest sprawdzenie, jak system radzi sobie z nowymi pytaniami i nową bazą wiedzy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ad81a1",
      "metadata": {
        "id": "80ad81a1"
      },
      "outputs": [],
      "source": [
        "# Przykład, stwórz własny zbiór!\n",
        "documents = [\n",
        "    \"Paris is the capital of France.\",\n",
        "    \"The dollar is the currency of the USA.\",\n",
        "    \"Python is a programming language that lets you work quickly.\"\n",
        "]\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "document_embeddings = [embedding_model.embed_query(doc) for doc in documents]\n",
        "document_embeddings_np = np.array(document_embeddings).astype('float32')\n",
        "\n",
        "index = faiss.IndexFlatL2(document_embeddings_np.shape[1])\n",
        "index.add(document_embeddings_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae5de7e3",
      "metadata": {
        "id": "ae5de7e3"
      },
      "outputs": [],
      "source": [
        "def generate_answer(query, top_k=2):\n",
        "    query_embedding = embedding_model.embed_query(query)\n",
        "    query_embedding_np = np.array(query_embedding).reshape(1, -1).astype('float32')\n",
        "\n",
        "    distances, indices = index.search(query_embedding_np, top_k)\n",
        "    retrieved_docs = \" \".join([documents[i] for i in indices[0]])\n",
        "\n",
        "    input_text = f\"question: {query} context: {retrieved_docs}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "    output = model.generate(input_ids)\n",
        "    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f46e708",
      "metadata": {
        "id": "4f46e708"
      },
      "outputs": [],
      "source": [
        "# Przykładowe testy (zmień pytania na swoje)\n",
        "questions = [\"What is the capital of France?\", \"What is the currency of USA?\"]\n",
        "\n",
        "for question in questions:\n",
        "    answer = generate_answer(question)\n",
        "    print(f\"Q: {question}\\nA: {answer}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f836e39",
      "metadata": {
        "id": "5f836e39"
      },
      "source": [
        "## Raport PDF\n",
        "**Twoje zadanie:** Przygotuj krótki raport PDF (1-2 strony) z opisem:\n",
        "- Jak przygotowałeś dane?\n",
        "- Jak wyglądały wyniki?\n",
        "- Jak działa RAG?  \n",
        "- Jakie widzisz ograniczenia RAG?  \n",
        "- Jakie są Twoje refleksje po eksperymencie z fine-tuningiem?   \n",
        "- Jak zmieniły się odpowiedzi po fine-tuningu?\n",
        "- Jak zmiana parametru k może wpłynąć na wyniki?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}